## Tutorials and Notes of Other Related Insightful Topics

1. Probabilistic Graphical Models: Lagrangian Relaxation Algorithms for Natural Language Processing [[Slides](http://people.csail.mit.edu/dsontag/courses/pgm12/slides/lecture3.pdf)]
2. Introduction to Conditional Random Fields [[Blog](http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/)]
3. Network Community Detection: A Review and Visual Survey [[Paper](https://arxiv.org/pdf/1708.00977.pdf)]
> * Section 2.3. Community Detection Techniques 
4. Fast unfolding of communities in large networks [[Paper](https://arxiv.org/pdf/0803.0476.pdf)]
> * [[A discussion of the Louvain method](https://www.quora.com/Is-there-a-simple-explanation-of-the-Louvain-Method-of-community-detection)], [[wiki of the Louvein Modularity](https://en.wikipedia.org/wiki/Louvain_Modularity)]
> * How do they design the function Q: Finding and evaluating community structure in networks [[Paper](https://arxiv.org/abs/cond-mat/0308217)]
5. A compendium of NP optimization problems [[Paper](https://www.semanticscholar.org/paper/A-compendium-of-NP-optimization-problems-Crescenzi-Kann/d5a16ac8dd6781090292b7db0a21e4240ffe56b0)]
6. [[Notes about LSH](https://blog.csdn.net/yc461515457/article/details/48845775)]
7. [[Survey about Min Hash Sketch](http://www.cohenwang.com/edith/Surveys/minhash.pdf)]
8. MinHash Tutorial with Python Code: [[Notes](https://mccormickml.com/2015/06/12/minhash-tutorial-with-python-code/)] [[Code](https://github.com/chrisjmccormick/MinHash)]
9. Must-read papers on GNN [[GitHub](https://github.com/thunlp/GNNPapers)]
10. Graph-based deap learning literatures [[GitHub](https://github.com/naganandy/graph-based-deep-learning-literature)]
11. Data Management for Machine Learning Applications [[Course site](https://thodrek.github.io/CS839_spring18/)]
12. Stanford CS224W: Machine Learning with Graphs [[Course site](http://web.stanford.edu/class/cs224w/)]
13. Explainability for Natural Language Processing (AAAI 2020 tutorial) [[Link](http://www.aacl2020.org/program/tutorials/#t4-explainability-for-natural-language-processing)] [[Video](https://www.youtube.com/watch?v=3tnrGe_JA0s&feature=youtu.be)]
14. Graph Mining & Learning (Neurips 2020 tutorial) [[Link](https://gm-neurips-2020.github.io)]
15. Discussion about GNN (Chinese) [[Link](https://developer.aliyun.com/article/741923?utm_content=g_1000099113)]
16. Stanford CS224n: Natural Language Processing with Deep Learning [[Course site](http://web.stanford.edu/class/cs224n/)]
17. Clique Relaxation Models in Networks: Theory, Algorithms, and Applications [[Slides](https://www.slideshare.net/ssakpi/clique-relaxation-models-in-networks-theory-algorithms-and-applications)]
18. KG Applications in Baidu (Chinese) [[Link](https://mp.weixin.qq.com/s/z3cp4PaAsA2zGLlgfYAtTg)]
19. Paper Digest (Database area) [[Link](https://www.paperdigest.org/category/database/)]
20. Complex Network (Collection of Notes and Tutorials) [[GitHub](https://github.com/LiuChuang0059/Complex-Network)]
21. INTRODUCTION TO GENERATIVE AI (NTU, Prof HUNG-YI LEE) [[Syllabus and Course Materials of Spring 2024](https://speech.ee.ntu.edu.tw/~hylee/genai/2024-spring.php)]
> * A very good and brief overview of Genearative AI! After listening to this course, you are able to clarify the important concepts in generative AI. For example, you can at least tell the difference between prompt engineering and fine-tuning (I think this is a very common mistake made by most people and even papers XD)
